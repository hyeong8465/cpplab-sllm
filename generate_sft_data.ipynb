{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì´ˆê¸° ë°ì´í„° ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°œë°œì ì§ë¬´ 30ê°œ\n",
    "developer_roles = [\n",
    "    (0, \"Software Engineer\"),\n",
    "    (1, \"Frontend Developer\"),\n",
    "    (2, \"Backend Developer\"),\n",
    "    (3, \"Full Stack Developer\"),\n",
    "    (4, \"DevOps Engineer\"),\n",
    "    (5, \"Cloud Engineer\"),\n",
    "    (6, \"Data Engineer\"),\n",
    "    (7, \"Machine Learning Engineer\"),\n",
    "    (8, \"AI Engineer\"),\n",
    "    (9, \"Embedded Software Engineer\"),\n",
    "    (10, \"Mobile Developer\"),\n",
    "    (11, \"iOS Developer\"),\n",
    "    (12, \"Android Developer\"),\n",
    "    (13, \"Game Developer\"),\n",
    "    (14, \"Blockchain Developer\"),\n",
    "    (15, \"Cybersecurity Engineer\"),\n",
    "    (16, \"Systems Engineer\"),\n",
    "    (17, \"Network Engineer\"),\n",
    "    (18, \"Database Administrator\"),\n",
    "    (19, \"QA Engineer\"),\n",
    "    (20, \"Test Automation Engineer\"),\n",
    "    (21, \"Site Reliability Engineer\"),\n",
    "    (22, \"IoT Developer\"),\n",
    "    (23, \"Big Data Engineer\"),\n",
    "    (24, \"Business Intelligence Developer\"),\n",
    "    (25, \"AR/VR Developer\"),\n",
    "    (26, \"Firmware Engineer\"),\n",
    "    (27, \"Solutions Architect\"),\n",
    "    (28, \"Technical Support Engineer\"),\n",
    "    (29, \"Software Architect\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡¬í”„íŠ¸\n",
    "template = \"\"\"\n",
    "ì•„ë˜ ì˜ˆì‹œ í˜•ì‹ì— ë§ê²Œ ê°œë°œìë¥¼ í¬ë§í•˜ëŠ” ì·¨ì—… ì¤€ë¹„ìƒì—ê²Œ í•„ìš”í•œ í”„ë¡œì íŠ¸ì˜ ê°œìš”ë¥¼ 10ê°œ ì‘ì„±í•´ì¤˜.\n",
    "\n",
    "ì§ë¬´: {role}\n",
    "\n",
    "<Example>\n",
    "'title': 'ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì˜ìƒ-ì–¸ì–´ ìœµí•© ëª¨ë¸ ê°œë°œ', 'description': 'ì˜ìƒê³¼ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìœµí•©í•˜ì—¬ ì •ë³´ë¥¼ ë¶„ì„í•˜ê³  ì˜ˆì¸¡í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ê°œë°œí•©ë‹ˆë‹¤. CNNê³¼ RNNì„ í™œìš©í•˜ì—¬ ë‹¤ì¤‘ ëª¨ë‹¬ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³ , ì‹¤í—˜ì„ í†µí•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê²€ì¦í•©ë‹ˆë‹¤.', 'projectgoal': 'ì˜ìƒ-ì–¸ì–´ ìœµí•© ê¸°ìˆ ì„ í†µí•´ ë‹¤ì–‘í•œ ì‘ìš© ê°€ëŠ¥ì„±ì„ íƒìƒ‰í•˜ê³ , ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ ë†’ì´ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.', 'techStacks': ['Python', 'TensorFlow', 'Keras', 'OpenCV'], 'qualifications': ['ê¸°ê³„í•™ìŠµ(ë”¥ëŸ¬ë‹), ì¸ê³µì§€ëŠ¥ ì „ë°˜ì— ëŒ€í•œ ì´ë¡ ì , ê¸°ìˆ ì  ì´í•´', 'ì˜ìƒ-ì–¸ì–´ ìœµí•© ë”¥ëŸ¬ë‹ ëª¨ë¸(CNNs, RNNs) ì„¤ê³„/ê°œë°œ ì—­ëŸ‰'], 'preferred_qualifications': ['ê¸°ê³„í•™ìŠµ(ë”¥ëŸ¬ë‹), ì´ë™ì²´(ì°¨ëŸ‰, ë¹„í–‰ì²´, ë¡œë´‡), ì¸ê³µì§€ëŠ¥ ê´€ë ¨ ìµœì‹  ë…¼ë¬¸ ì´í•´ ë° ê¸°ë²• ì¬ êµ¬í˜„ ëŠ¥ë ¥', 'ì¸ê³µì§€ëŠ¥ ê´€ë ¨ ê°œë°œ ì§€ì‹/ê²½í—˜ ë³´ìœ  ë° ì„ë² ë””ë“œ ê²½í—˜'], 'userskillgaps': ['AI ì‹ ê¸°ìˆ  í‰ê°€ ë° ê²€ì¦ì„ ìœ„í•œ ì‹¤í—˜ ì„¤ê³„ ë° ì‹¤í—˜ ìˆ˜í–‰ ì—­ëŸ‰', 'í™•ë¥  ë° í†µê³„, ì„ í˜•ëŒ€ìˆ˜, í•´ì„í•™ ê¸°ë°˜ì˜ ìˆ˜í•™ì  ëª¨ë¸ë§ì— ëŒ€í•œ ì´í•´']\n",
    "</Example>\n",
    "\n",
    "<output_format>\n",
    "{format_instructions}\n",
    "</output_format>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output í˜•ì‹\n",
    "os.chdir('/Users/no.2/Desktop/GitHub/cpplab-ai/project')\n",
    "from models.project_info import Theme\n",
    "class Themes(BaseModel):\n",
    "    themes: List[Theme] = Field(..., description=\"ìƒì„±ëœ í”„ë¡œì íŠ¸ ê°œìš”ì˜ ë¦¬ìŠ¤íŠ¸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain ìƒì„±\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "prompt =  PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['role']\n",
    ")\n",
    "parser = JsonOutputParser(pydantic_object=Themes)\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data(í”„ë¡œì íŠ¸ ê°œìš”) ìƒì„±\n",
    "import asyncio\n",
    "import json\n",
    "\n",
    "# ì§êµ° ë¦¬ìŠ¤íŠ¸, developer_roles ì‚¬ìš©\n",
    "# ë¹„ë™ê¸° í˜¸ì¶œì„ ìœ„í•œ í•¨ìˆ˜ ì •ì˜\n",
    "async def generate_project_data(role):\n",
    "    input_data = {\"role\": role}\n",
    "    result = await chain.ainvoke(input_data)\n",
    "    print(f\"Completed: {role}\")\n",
    "    return {role: result}\n",
    "\n",
    "# ëª¨ë“  ì§êµ°ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ë¹„ë™ê¸°ë¡œ ìˆ˜ì§‘\n",
    "async def main():\n",
    "    tasks = [generate_project_data(role) for role in developer_roles]\n",
    "\n",
    "    # ëª¨ë“  ì‘ì—…ì„ ë³‘ë ¬ì ìœ¼ë¡œ ì‹¤í–‰\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "    with open(\"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/base/all_roles_input.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(\"All roles processed and saved!\")\n",
    "\n",
    "# ë¹„ë™ê¸° ì‹¤í–‰\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data(í”„ë¡œì íŠ¸ ê°€ì´ë“œë¼ì¸) ìƒì„±\n",
    "import asyncio\n",
    "import json\n",
    "\n",
    "os.chdir('/Users/no.2/Desktop/GitHub/cpplab-ai/project/services')\n",
    "from chain_generator import gendetails_chain\n",
    "\n",
    "# ì§êµ° ë¦¬ìŠ¤íŠ¸, developer_rolesë¥¼ ì‚¬ìš©\n",
    "\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "# ë¹„ë™ê¸° í˜¸ì¶œì„ ìœ„í•œ í•¨ìˆ˜ ì •ì˜\n",
    "async def generate_output_data(theme, retries=0):\n",
    "    chain = gendetails_chain()\n",
    "\n",
    "    try:\n",
    "        result = await chain.ainvoke(\n",
    "            input={\n",
    "                \"recommended_project\": theme\n",
    "            }\n",
    "        )\n",
    "        print(f\"Completed: {theme['title']}\")\n",
    "        return {theme['title']: result}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {theme['title']}: {e}\")\n",
    "        if retries < MAX_RETRIES:\n",
    "            print(f\"Retrying {theme['title']} ({retries + 1}/{MAX_RETRIES})\")\n",
    "            return await generate_output_data(theme, retries=retries + 1)\n",
    "        else:\n",
    "            print(f\"Failed to process {theme['title']} after {MAX_RETRIES} attempts\")\n",
    "            return {theme['title']: None}\n",
    "\n",
    "# ëª¨ë“  ì§êµ°ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ë¹„ë™ê¸°ë¡œ ìˆ˜ì§‘\n",
    "async def main(i, role):\n",
    "    # JSON íŒŒì¼ ê²½ë¡œ\n",
    "    input_path = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/base/all_roles_input.json\"\n",
    "    output_path = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/base/all_roles_output.json\"\n",
    "\n",
    "    # íŒŒì¼ ì½ê¸°\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    tasks = [generate_output_data(theme) for theme in data[i][role][\"themes\"]]\n",
    "    \n",
    "    # ëª¨ë“  ì‘ì—…ì„ ë³‘ë ¬ì ìœ¼ë¡œ ì‹¤í–‰\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    # ê¸°ì¡´ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (ë®ì–´ì“°ì§€ ì•Šë„ë¡)\n",
    "    try:\n",
    "        with open(output_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "            existing_results = json.load(json_file)\n",
    "    except FileNotFoundError:\n",
    "        existing_results = []\n",
    "\n",
    "    # ìƒˆë¡œìš´ ê²°ê³¼ ì¶”ê°€\n",
    "    existing_results.extend(results)\n",
    "\n",
    "    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(existing_results, json_file, ensure_ascii=False, indent=4)\n",
    "    print(f\"Completed processing for role: {role}\")\n",
    "\n",
    "# ë¹„ë™ê¸° ì‹¤í–‰\n",
    "for i, role in developer_roles:\n",
    "    await main(i, role)\n",
    "    print(f\"Completed processing for role: {role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒì„±ëœ ë°ì´í„° í™•ì¸ 274ê°œ\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# JSON íŒŒì¼ ê²½ë¡œ\n",
    "file_path = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/base/\"\n",
    "\n",
    "# íŒŒì¼ ì½ê¸°\n",
    "with open(file_path + \"all_roles_input.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    inputs = json.load(file)\n",
    "with open(file_path + \"all_roles_output.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    outputs = json.load(file)\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "data = []\n",
    "j = 0\n",
    "for i, role in developer_roles:\n",
    "    for theme in inputs[i][role]['themes']:\n",
    "        data.append({\n",
    "            'role': role,\n",
    "            'input': theme,\n",
    "            'output': outputs[j][theme['title']]\n",
    "        })\n",
    "        j += 1\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['difficultyLevel'] = df['output'].apply(lambda x: x.get('difficultyLevel', None))\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë‚œì´ë„ ë³€ê²½(ì´ˆê¸‰, ê³ ê¸‰ ì¶”ê°€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡¬í”„íŠ¸\n",
    "template = \"\"\"\n",
    "<Role>\n",
    "ë„Œ í”„ë¡œì íŠ¸ ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì•¼. ì¼ë°˜ì ì¸ í”„ë¡œì íŠ¸ ì£¼ì œë¥¼ êµ¬ì²´í™”í•˜ê³ , ì„¸ë¶€ ë‹¨ê³„ë¥¼ êµ¬ì„±í•˜ëŠ”ë° íŠ¹í™”ë˜ì–´ ìˆì–´.\n",
    "ì´ì „ í”„ë¡œì íŠ¸ì¸ 'prev_project'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©ìì˜ í¬ë§ ë‚œì´ë„ë¥¼ ë°˜ì˜í•´ì„œ í”„ë¡œì íŠ¸ë¥¼ êµ¬ì²´í™” í•´ì¤˜.\n",
    "</Role>\n",
    "\n",
    "<instructions>\n",
    "- Read through the all the below sections to get an understanding of the task.\n",
    "- í”„ë¡œì íŠ¸ëŠ” 6ë‹¨ê³„ë¡œ ë‚˜ëˆ„ê³ , ê° ë‹¨ê³„ë³„ ì„¸ë¶€ Taskë¥¼ í¬í•¨í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "- ì„¸ë¶€ Taskì˜ ì‘ì—… ë‹¨ìœ„ëŠ” ìµœëŒ€í•œ ì‘ê³  ì„¸ì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "- ê° TaskëŠ” êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ í¬í•¨í•´ ëª…í™•íˆ ì‘ì„±í•˜ì„¸ìš”.\n",
    "- ê° ì„¸ë¶€ Taskë§ˆë‹¤ í•™ìŠµì— ë„ì›€ì´ ë˜ëŠ” ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ê°™ì´ ì¶œë ¥í•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, Taskì˜ ë‚´ìš©ì´ 'ë°ì´í„° ìˆ˜ì§‘'ì´ë¼ë©´ 'Kaggle', 'AIHub'ì™€ ê°™ì€ ë°ì´í„° í”Œë«í¼ì„ ê°™ì´ ì œê³µí•´ì¤˜.\n",
    "- ì‚¬ìš©ì í˜¼ì ë‘ ë‹¬ê°„ ì§„í–‰í•˜ëŠ” í”„ë¡œì íŠ¸ì„ì„ ê°ì•ˆí•´ì„œ Taskë¥¼ ì‘ì„±í•´\n",
    "- ê²°ê³¼ëŠ” ë°˜ë“œì‹œ í•œê¸€ë¡œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "</instructions>\n",
    "\n",
    "<prev_project>\n",
    "{prev_project}\n",
    "</prev_project>\n",
    "\n",
    "<hope>\n",
    "í¬ë§ ë‚œì´ë„: {hopeLevel}\n",
    "</hope>\n",
    "\n",
    "<Output_Format>\n",
    "{format_instructions}\n",
    "</Output_Format>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output í˜•ì‹\n",
    "os.chdir('/Users/no.2/Desktop/GitHub/cpplab-ai/project')\n",
    "from models.project_info import Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain ìƒì„±\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "prompt =  PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['prev_project', 'hopeLevel']\n",
    ")\n",
    "parser = JsonOutputParser(pydantic_object=Project)\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‚œì´ë„ ë³€ê²½ ë°ì´í„° ìƒì„±\n",
    "import asyncio\n",
    "import json\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "# ë™ì‹œ ì‘ì—… ìˆ˜ ì œí•œ\n",
    "semaphore = asyncio.Semaphore(10)\n",
    "\n",
    "# ë¹„ë™ê¸° í˜¸ì¶œì„ ìœ„í•œ í•¨ìˆ˜ ì •ì˜\n",
    "async def generate_project_data(prev_project, hopeLevel):\n",
    "    async with semaphore:  # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ í˜¸ì¶œ ì œí•œ\n",
    "        input_data = {\"prev_project\": prev_project, \"hopeLevel\": hopeLevel}\n",
    "        result = await chain.ainvoke(input_data)\n",
    "        print(f\"Completed: {prev_project['title']} ({hopeLevel})\")\n",
    "        return result\n",
    "\n",
    "# ì‰½ê²Œ, ì–´ë µê²Œ ë¹„ë™ê¸° ìƒì„±\n",
    "async def main():\n",
    "    tasks_easy = [generate_project_data(prev_project, 'ì‰½ê²Œ') for prev_project in df['output'].tolist()]\n",
    "    tasks_hard = [generate_project_data(prev_project, 'ì–´ë µê²Œ') for prev_project in df['output'].tolist()]\n",
    "    tasks = tasks_easy + tasks_hard\n",
    "\n",
    "    # ëª¨ë“  ì‘ì—…ì„ ë³‘ë ¬ì ìœ¼ë¡œ ì‹¤í–‰\n",
    "    results = await tqdm.gather(*tasks, desc=\"Processing Projects\", total=len(tasks))\n",
    "\n",
    "    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "    with open(\"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/output_level.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "    print(\"Done!\")\n",
    "\n",
    "# ë¹„ë™ê¸° ì‹¤í–‰\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒì„±ëœ ë°ì´í„° í™•ì¸\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# JSON íŒŒì¼ ê²½ë¡œ\n",
    "file_path = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/\"\n",
    "\n",
    "# íŒŒì¼ ì½ê¸°\n",
    "with open(file_path + \"output_level.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    output_level = json.load(file)\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "output_level_df = pd.DataFrame({'output': output_level})\n",
    "output_level_df['difficultyLevel'] = output_level_df['output'].apply(lambda x: x['difficultyLevel'])\n",
    "output_level_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded = pd.concat([df] * 3, ignore_index=True)\n",
    "df_expanded.loc[274:, 'output'] = output_level_df['output'].values\n",
    "df_expanded.loc[274:, 'difficultyLevel'] = output_level_df['difficultyLevel'].values\n",
    "df_base_level = df_expanded.copy()\n",
    "df_base_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë„ë©”ì¸ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_domains = [\n",
    "    \"ê¸ˆìœµ(FinTech)\",  # ëª¨ë°”ì¼ ê²°ì œ, ì•”í˜¸í™”í, ì•Œê³ ë¦¬ì¦˜ íŠ¸ë ˆì´ë”©\n",
    "    \"ì „ììƒê±°ë˜(E-Commerce)\",  # ì•„ë§ˆì¡´, ì¿ íŒ¡, ì‡¼í”¼íŒŒì´ ë“± ì˜¨ë¼ì¸ ì‡¼í•‘ í”Œë«í¼\n",
    "    \"ì˜ë£Œ/í—¬ìŠ¤ì¼€ì–´(HealthTech)\",  # ì›ê²© ì˜ë£Œ, AI ì§„ë‹¨, ì˜ë£Œ ë°ì´í„° ë¶„ì„\n",
    "    \"ê²Œì„(Game Development)\",  # ê²Œì„ ì—”ì§„, í´ë¼ìš°ë“œ ê²Œì´ë°, VR/AR ê²Œì„\n",
    "    \"ììœ¨ì£¼í–‰(Autonomous Vehicles)\",  # í…ŒìŠ¬ë¼, ììœ¨ì£¼í–‰ ìë™ì°¨, ë“œë¡  ê¸°ìˆ \n",
    "    \"ì‚¬ì´ë²„ ë³´ì•ˆ(Cybersecurity)\",  # í•´í‚¹ ë°©ì§€, ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ, ë°ì´í„° ì•”í˜¸í™”\n",
    "    \"í´ë¼ìš°ë“œ ì»´í“¨íŒ…(Cloud Computing)\",  # AWS, Azure, GCP ê°™ì€ í´ë¼ìš°ë“œ ì¸í”„ë¼\n",
    "    \"ì‚¬ë¬¼ì¸í„°ë„·(IoT, Internet of Things)\",  # ìŠ¤ë§ˆíŠ¸ í™ˆ, ìŠ¤ë§ˆíŠ¸ ì‹œí‹°, ì‚°ì—… IoT\n",
    "    \"ë¸”ë¡ì²´ì¸(Blockchain)\",  # ì•”í˜¸í™”í, ìŠ¤ë§ˆíŠ¸ ì»¨íŠ¸ë™íŠ¸, íƒˆì¤‘ì•™í™” ì• í”Œë¦¬ì¼€ì´ì…˜\n",
    "    \"ë©”íƒ€ë²„ìŠ¤(Metaverse)\",  # VR/AR ê¸°ë°˜ ê°€ìƒ ì„¸ê³„, ë””ì§€í„¸ íŠ¸ìœˆ, NFT ê¸°ë°˜ ê°€ìƒ ê²½ì œ\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡¬í”„íŠ¸\n",
    "template = \"\"\"\n",
    "ì•„ë˜ í”„ë¡œì íŠ¸ ê°œìš”ì— IT ë„ë©”ì¸ì„ ì ìš©í•´ì„œ í”„ë¡œì íŠ¸ ê°œìš”ë¥¼ ìˆ˜ì •í•´ì¤˜.\n",
    "\n",
    "í”„ë¡œì íŠ¸ ê°œìš”: {input_project}\n",
    "IT ë„ë©”ì¸: {it_domain}\n",
    "\n",
    "<output_format>\n",
    "{format_instructions}\n",
    "</output_format>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output í˜•ì‹\n",
    "os.chdir('/Users/no.2/Desktop/GitHub/cpplab-ai/project')\n",
    "from models.project_info import Theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain ìƒì„±\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "prompt =  PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['input_project', 'it_domain']\n",
    ")\n",
    "parser = JsonOutputParser(pydantic_object=Theme)\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_domain (ë„ë©”ì¸ì´ ì¶”ê°€ëœ í”„ë¡œì íŠ¸ ê°œìš”) ìƒì„±\n",
    "import asyncio\n",
    "import json\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "# ë™ì‹œ ì‘ì—… ìˆ˜ ì œí•œ\n",
    "semaphore = asyncio.Semaphore(15)\n",
    "\n",
    "# ë„ë©”ì¸ ë¦¬ìŠ¤íŠ¸, it_domains ì‚¬ìš©\n",
    "\n",
    "# ë¹„ë™ê¸° í˜¸ì¶œì„ ìœ„í•œ í•¨ìˆ˜ ì •ì˜\n",
    "async def generate_project_data(input_project, it_domain):\n",
    "    async with semaphore:\n",
    "        input_data = {\"input_project\": input_project, \"it_domain\": it_domain}\n",
    "        result = await chain.ainvoke(input_data)\n",
    "        print(f\"Completed: {input_project['title']} ({it_domain})\")\n",
    "        return result\n",
    "\n",
    "# ëª¨ë“  ì§êµ°ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ë¹„ë™ê¸°ë¡œ ìˆ˜ì§‘\n",
    "async def main():\n",
    "    tasks = []\n",
    "    for input_project in df['input'].tolist():\n",
    "        for it_domain in it_domains:\n",
    "            tasks.append(generate_project_data(input_project, it_domain))\n",
    "\n",
    "    # ëª¨ë“  ì‘ì—…ì„ ë³‘ë ¬ì ìœ¼ë¡œ ì‹¤í–‰\n",
    "    results = await tqdm.gather(*tasks, desc=\"Processing Projects\", total=len(tasks))\n",
    "\n",
    "    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "    with open(\"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/input_domain.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "    print(\"All roles processed and saved!\")\n",
    "\n",
    "# ë¹„ë™ê¸° ì‹¤í–‰\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data(ë„ë©”ì¸ì´ ì¶”ê°€ëœ í”„ë¡œì íŠ¸ ê°€ì´ë“œë¼ì¸) ìƒì„±\n",
    "import asyncio\n",
    "import json\n",
    "from tqdm.asyncio import tqdm  # tqdmì˜ ë¹„ë™ê¸° ì§€ì› ëª¨ë“ˆ\n",
    "\n",
    "os.chdir('/Users/no.2/Desktop/GitHub/cpplab-ai/project/services')\n",
    "from chain_generator import gendetails_chain\n",
    "\n",
    "# ë™ì‹œ ì‘ì—… ìˆ˜ ì œí•œ\n",
    "semaphore = asyncio.Semaphore(10)\n",
    "\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "# ë¹„ë™ê¸° í˜¸ì¶œì„ ìœ„í•œ í•¨ìˆ˜ ì •ì˜\n",
    "async def generate_output_data(input, index, retries=0):\n",
    "    async with semaphore:\n",
    "        chain = gendetails_chain()\n",
    "        try:\n",
    "            result = await chain.ainvoke(\n",
    "                input={\n",
    "                    \"recommended_project\": input\n",
    "                }\n",
    "            )\n",
    "            # print(f\"Completed: {input['title']}\")\n",
    "            return (index, result)  # âœ… ì›ë˜ ìˆœì„œ(index)ì™€ ê²°ê³¼ë¥¼ í•¨ê»˜ ë°˜í™˜\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {input['title']}: {e}\")\n",
    "            if retries < MAX_RETRIES:\n",
    "                print(f\"Retrying {input['title']} ({retries + 1}/{MAX_RETRIES})\")\n",
    "                return await generate_output_data(input, retries=retries + 1)\n",
    "            else:\n",
    "                print(f\"Failed to process {input['title']} after {MAX_RETRIES} attempts\")\n",
    "                return (index, {input['title']: None})  # âœ… ì‹¤íŒ¨í•œ ê²½ìš°ë„ ì¸ë±ìŠ¤ë¥¼ í¬í•¨í•˜ì—¬ ë°˜í™˜\n",
    "\n",
    "# ëª¨ë“  ì§êµ°ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ë¹„ë™ê¸°ë¡œ ìˆ˜ì§‘\n",
    "async def main():\n",
    "    # JSON íŒŒì¼ ê²½ë¡œ\n",
    "    input_path = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/input_domain.json\"\n",
    "    output_path = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/output_domain.json\"\n",
    "\n",
    "    # íŒŒì¼ ì½ê¸°\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    total_tasks = len(data)\n",
    "    progress_bar = tqdm(total=total_tasks, desc=\"Processing Projects\", unit=\"task\", disable=True)\n",
    "\n",
    "    results = [None] * total_tasks  # âœ… Noneì„ ì±„ìš´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¯¸ë¦¬ ìƒì„±\n",
    "    completed_count = 0\n",
    "\n",
    "    # ë¹„ë™ê¸° ì‘ì—… ì‹¤í–‰ ë° ì§„í–‰ë„ ì—…ë°ì´íŠ¸\n",
    "    tasks = [generate_output_data(d, i) for i, d in enumerate(data)]  # âœ… ì›ë˜ ì¸ë±ìŠ¤ í¬í•¨\n",
    "\n",
    "    for future in asyncio.as_completed(tasks):\n",
    "        index, result = await future\n",
    "        results[index] = result\n",
    "        completed_count += 1\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        # 10ê°œ ë‹¨ìœ„ë¡œ ì§„í–‰ë¥  ì¶œë ¥\n",
    "        if completed_count % 10 == 0:\n",
    "            progress_bar.n = completed_count  # âœ… tqdm ì§„í–‰ë¥ ì„ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •\n",
    "            progress_bar.refresh()  # âœ… tqdm ìˆ˜ë™ ì—…ë°ì´íŠ¸\n",
    "            print(f\"âœ… {completed_count}/{total_tasks} tasks completed.\")\n",
    "\n",
    "    progress_bar.close()    \n",
    "\n",
    "    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# ë¹„ë™ê¸° ì‹¤í–‰\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "data = json.load(open(\"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/input_domain.json\"))\n",
    "output_data = json.load(open(\"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/output_domain.json\"))\n",
    "df_domain = pd.DataFrame(columns=['input'])\n",
    "df_domain['input'] = data\n",
    "df_domain['output'] = output_data\n",
    "df_domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë„ë©”ì¸ ì¶”ê°€ + ë‚œì´ë„ ë³€ê²½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "# í”„ë¡¬í”„íŠ¸\n",
    "template = \"\"\"\n",
    "<Role>\n",
    "ë„Œ í”„ë¡œì íŠ¸ ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì•¼. ì¼ë°˜ì ì¸ í”„ë¡œì íŠ¸ ì£¼ì œë¥¼ êµ¬ì²´í™”í•˜ê³ , ì„¸ë¶€ ë‹¨ê³„ë¥¼ êµ¬ì„±í•˜ëŠ”ë° íŠ¹í™”ë˜ì–´ ìˆì–´.\n",
    "ì´ì „ í”„ë¡œì íŠ¸ì¸ 'prev_project'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©ìì˜ í¬ë§ ë‚œì´ë„ë¥¼ ë°˜ì˜í•´ì„œ í”„ë¡œì íŠ¸ë¥¼ êµ¬ì²´í™” í•´ì¤˜.\n",
    "</Role>\n",
    "\n",
    "<instructions>\n",
    "- Read through the all the below sections to get an understanding of the task.\n",
    "- í”„ë¡œì íŠ¸ëŠ” 6ë‹¨ê³„ë¡œ ë‚˜ëˆ„ê³ , ê° ë‹¨ê³„ë³„ ì„¸ë¶€ Taskë¥¼ í¬í•¨í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "- ì„¸ë¶€ Taskì˜ ì‘ì—… ë‹¨ìœ„ëŠ” ìµœëŒ€í•œ ì‘ê³  ì„¸ì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "- ê° TaskëŠ” êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ í¬í•¨í•´ ëª…í™•íˆ ì‘ì„±í•˜ì„¸ìš”.\n",
    "- ê° ì„¸ë¶€ Taskë§ˆë‹¤ í•™ìŠµì— ë„ì›€ì´ ë˜ëŠ” ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ê°™ì´ ì¶œë ¥í•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, Taskì˜ ë‚´ìš©ì´ 'ë°ì´í„° ìˆ˜ì§‘'ì´ë¼ë©´ 'Kaggle', 'AIHub'ì™€ ê°™ì€ ë°ì´í„° í”Œë«í¼ì„ ê°™ì´ ì œê³µí•´ì¤˜.\n",
    "- ì‚¬ìš©ì í˜¼ì ë‘ ë‹¬ê°„ ì§„í–‰í•˜ëŠ” í”„ë¡œì íŠ¸ì„ì„ ê°ì•ˆí•´ì„œ Taskë¥¼ ì‘ì„±í•´\n",
    "- ê²°ê³¼ëŠ” ë°˜ë“œì‹œ í•œê¸€ë¡œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "</instructions>\n",
    "\n",
    "<prev_project>\n",
    "{prev_project}\n",
    "</prev_project>\n",
    "\n",
    "<hope>\n",
    "í¬ë§ ë‚œì´ë„: {hopeLevel}\n",
    "</hope>\n",
    "\n",
    "<Output_Format>\n",
    "{format_instructions}\n",
    "</Output_Format>\n",
    "\"\"\"\n",
    "# output í˜•ì‹\n",
    "os.chdir('/Users/no.2/Desktop/GitHub/cpplab-ai/project')\n",
    "from models.project_info import Project\n",
    "\n",
    "# chain ìƒì„±\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "prompt =  PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['prev_project', 'hopeLevel']\n",
    ")\n",
    "parser = JsonOutputParser(pydantic_object=Project)\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# ë‚œì´ë„ ë³€ê²½ ë°ì´í„° ìƒì„±\n",
    "import asyncio\n",
    "import json\n",
    "from tqdm.asyncio import tqdm  # tqdmì˜ ë¹„ë™ê¸° ì§€ì› ëª¨ë“ˆ\n",
    "\n",
    "# ë™ì‹œ ì‘ì—… ìˆ˜ ì œí•œ\n",
    "semaphore = asyncio.Semaphore(20)\n",
    "\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "# ë¹„ë™ê¸° í˜¸ì¶œì„ ìœ„í•œ í•¨ìˆ˜ ì •ì˜\n",
    "async def generate_project_data(index, prev_project, hopeLevel, retries=0):\n",
    "    async with semaphore:  # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ í˜¸ì¶œ ì œí•œ\n",
    "        input_data = {\"prev_project\": prev_project, \"hopeLevel\": hopeLevel}\n",
    "        try:\n",
    "            result = await chain.ainvoke(input_data)\n",
    "            return (index, result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {prev_project['title']}: {e}\")\n",
    "            if retries < MAX_RETRIES:\n",
    "                print(f\"Retrying {prev_project['title']} ({retries + 1}/{MAX_RETRIES})\")\n",
    "                return await generate_project_data(index, prev_project, hopeLevel, retries=retries + 1)\n",
    "            else:\n",
    "                print(f\"Failed to process {prev_project['title']} after {MAX_RETRIES} attempts\")\n",
    "                return (index, None)\n",
    "\n",
    "# ì‰½ê²Œ, ì–´ë µê²Œ ë¹„ë™ê¸° ìƒì„±\n",
    "async def main():\n",
    "    tasks_easy = [generate_project_data(i, prev_project, 'ì‰½ê²Œ') for i, prev_project in enumerate(df_domain['output'].tolist())]\n",
    "    tasks_hard = [generate_project_data(i+len(tasks_easy), prev_project, 'ì–´ë µê²Œ') for i, prev_project in enumerate(df_domain['output'].tolist())]\n",
    "    tasks = tasks_easy + tasks_hard\n",
    "\n",
    "    total_tasks = len(tasks)\n",
    "    progress_bar = tqdm(total=total_tasks, desc=\"Processing Projects\", unit=\"task\", disable=False)\n",
    "\n",
    "    results = [None] * total_tasks  # âœ… Noneì„ ì±„ìš´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¯¸ë¦¬ ìƒì„±\n",
    "    completed_count = 0\n",
    "\n",
    "    for future in asyncio.as_completed(tasks):\n",
    "        index, result = await future\n",
    "        results[index] = result\n",
    "        completed_count += 1\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        # 10ê°œ ë‹¨ìœ„ë¡œ ì§„í–‰ë¥  ì¶œë ¥ ë° ì €ì¥\n",
    "        if completed_count % 100 == 0:\n",
    "            progress_bar.n = completed_count  # âœ… tqdm ì§„í–‰ë¥ ì„ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •\n",
    "            progress_bar.refresh()  # âœ… tqdm ìˆ˜ë™ ì—…ë°ì´íŠ¸\n",
    "            with open(\"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/output_domain_level.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "                json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    progress_bar.close()    \n",
    "\n",
    "    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "    with open(\"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/output_domain_level.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "    print(\"Done!\")\n",
    "\n",
    "# ë¹„ë™ê¸° ì‹¤í–‰\n",
    "# await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from tqdm.asyncio import tqdm  # ë¹„ë™ê¸° tqdm\n",
    "\n",
    "# ì €ì¥ëœ ë°ì´í„° ê²½ë¡œ\n",
    "OUTPUT_FILE = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/output_domain_level.json\"\n",
    "FAILED_REQUESTS_FILE = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/failed_requests.json\"\n",
    "\n",
    "# ë™ì‹œ ì‘ì—… ìˆ˜ ì œí•œ\n",
    "semaphore = asyncio.Semaphore(10)\n",
    "MAX_RETRIES = 3  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜\n",
    "\n",
    "# ê¸°ì¡´ ì €ì¥ëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            results = json.load(f)\n",
    "            print(f\"âœ… ê¸°ì¡´ ì €ì¥ëœ ë°ì´í„° ë¡œë“œ ì„±ê³µ ({len(results)}ê°œ)\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"âš ï¸ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨. ìƒˆë¡œìš´ íŒŒì¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "            results = []\n",
    "else:\n",
    "    results = []\n",
    "\n",
    "# Noneì¸ ë°ì´í„°ë§Œ ë‹¤ì‹œ ì‹¤í–‰í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "retry_indices = [i for i, result in enumerate(results) if result is None]\n",
    "print(f\"âš ï¸ {len(retry_indices)}ê°œì˜ ì‹¤íŒ¨í•œ ì‘ì—…ì„ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ì‹¤íŒ¨í•œ ìš”ì²­ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "failed_requests = []\n",
    "\n",
    "# ë¹„ë™ê¸° í˜¸ì¶œì„ ìœ„í•œ í•¨ìˆ˜ ì •ì˜\n",
    "async def generate_project_data(index, prev_project, hopeLevel, retries=0):\n",
    "    async with semaphore:  # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ í˜¸ì¶œ ì œí•œ\n",
    "        input_data = {\"prev_project\": prev_project, \"hopeLevel\": hopeLevel}\n",
    "        try:\n",
    "            result = await chain.ainvoke(input_data)\n",
    "            return index, result\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {prev_project['title']} - {e}\")\n",
    "            if retries < MAX_RETRIES:\n",
    "                print(f\"ğŸ”„ ì¬ì‹œë„ {retries + 1}/{MAX_RETRIES} - {prev_project['title']}\")\n",
    "                return await generate_project_data(index, prev_project, hopeLevel, retries=retries + 1)\n",
    "            else:\n",
    "                print(f\"âš ï¸ {prev_project['title']} ì²˜ë¦¬ ì‹¤íŒ¨ (ìµœëŒ€ ì¬ì‹œë„ ë„ë‹¬)\")\n",
    "                failed_requests.append({\"index\": index, \"prev_project\": prev_project, \"hopeLevel\": hopeLevel})\n",
    "                return index, None  # ì‹¤íŒ¨í•œ ìš”ì²­ì€ None ë°˜í™˜\n",
    "\n",
    "# Noneì¸ ê°’ë§Œ ë‹¤ì‹œ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜\n",
    "async def retry_failed_tasks():\n",
    "    progress_bar = tqdm(total=len(retry_indices), desc=\"Retrying Failed Tasks\", unit=\"task\", disable=False)\n",
    "\n",
    "    tasks = [generate_project_data(i, df_domain['output'].tolist()[i % len(df_domain)], \"ì‰½ê²Œ\" if i < len(df_domain) else \"ì–´ë µê²Œ\") for i in retry_indices]\n",
    "\n",
    "    completed_count = 0\n",
    "\n",
    "    for future in asyncio.as_completed(tasks):\n",
    "        index, result = await future\n",
    "        results[index] = result\n",
    "        completed_count += 1\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        # 10ê°œ ë‹¨ìœ„ë¡œ ì§„í–‰ë¥  ì¶œë ¥ ë° ì €ì¥\n",
    "        if completed_count % 10 == 0:\n",
    "            progress_bar.n = completed_count\n",
    "            # progress_bar.refresh()\n",
    "            with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as json_file:\n",
    "                json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # ìµœì¢… ê²°ê³¼ ì €ì¥\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # ì‹¤íŒ¨í•œ ìš”ì²­ ì €ì¥\n",
    "    if failed_requests:\n",
    "        with open(FAILED_REQUESTS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(failed_requests, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"âš ï¸ {len(failed_requests)}ê°œ ìš”ì²­ ì‹¤íŒ¨. {FAILED_REQUESTS_FILE}ì— ì €ì¥ë¨.\")\n",
    "\n",
    "    print(\"ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!\")\n",
    "\n",
    "# ë¹„ë™ê¸° ì‹¤í–‰\n",
    "await retry_failed_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV íŒŒì¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°œë°œì ì§ë¬´ 30ê°œ\n",
    "developer_roles = [\n",
    "    (0, \"Software Engineer\"),\n",
    "    (1, \"Frontend Developer\"),\n",
    "    (2, \"Backend Developer\"),\n",
    "    (3, \"Full Stack Developer\"),\n",
    "    (4, \"DevOps Engineer\"),\n",
    "    (5, \"Cloud Engineer\"),\n",
    "    (6, \"Data Engineer\"),\n",
    "    (7, \"Machine Learning Engineer\"),\n",
    "    (8, \"AI Engineer\"),\n",
    "    (9, \"Embedded Software Engineer\"),\n",
    "    (10, \"Mobile Developer\"),\n",
    "    (11, \"iOS Developer\"),\n",
    "    (12, \"Android Developer\"),\n",
    "    (13, \"Game Developer\"),\n",
    "    (14, \"Blockchain Developer\"),\n",
    "    (15, \"Cybersecurity Engineer\"),\n",
    "    (16, \"Systems Engineer\"),\n",
    "    (17, \"Network Engineer\"),\n",
    "    (18, \"Database Administrator\"),\n",
    "    (19, \"QA Engineer\"),\n",
    "    (20, \"Test Automation Engineer\"),\n",
    "    (21, \"Site Reliability Engineer\"),\n",
    "    (22, \"IoT Developer\"),\n",
    "    (23, \"Big Data Engineer\"),\n",
    "    (24, \"Business Intelligence Developer\"),\n",
    "    (25, \"AR/VR Developer\"),\n",
    "    (26, \"Firmware Engineer\"),\n",
    "    (27, \"Solutions Architect\"),\n",
    "    (28, \"Technical Support Engineer\"),\n",
    "    (29, \"Software Architect\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = \"\"\"\n",
    "<Role>\n",
    "ë„Œ í”„ë¡œì íŠ¸ ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì•¼. ì¼ë°˜ì ì¸ í”„ë¡œì íŠ¸ ì£¼ì œë¥¼ êµ¬ì²´í™”í•˜ê³ , ì„¸ë¶€ ë‹¨ê³„ë¥¼ êµ¬ì„±í•˜ëŠ”ë° íŠ¹í™”ë˜ì–´ ìˆì–´.\n",
    "ì¶”ì²œ í”„ë¡œì íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•„ë˜ ì§€ì‹œì‚¬í•­ì— ë§ì¶°ì„œ í”„ë¡œì íŠ¸ë¥¼ êµ¬ì²´í™”í•´ì¤˜.\n",
    "</Role>\n",
    "\n",
    "<instructions>\n",
    "- Read through the all the below sections to get an understanding of the task.\n",
    "- í”„ë¡œì íŠ¸ëŠ” 6ë‹¨ê³„ë¡œ ë‚˜ëˆ„ê³ , ê° ë‹¨ê³„ë³„ ì„¸ë¶€ Taskë¥¼ í¬í•¨í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "- ì„¸ë¶€ Taskì˜ ì‘ì—… ë‹¨ìœ„ëŠ” ìµœëŒ€í•œ ì‘ê³  ì„¸ì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "- ê° TaskëŠ” êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ í¬í•¨í•´ ëª…í™•íˆ ì‘ì„±í•˜ì„¸ìš”.\n",
    "- ê° ì„¸ë¶€ Taskë§ˆë‹¤ í•™ìŠµì— ë„ì›€ì´ ë˜ëŠ” ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ê°™ì´ ì¶œë ¥í•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, Taskì˜ ë‚´ìš©ì´ 'ë°ì´í„° ìˆ˜ì§‘'ì´ë¼ë©´ 'Kaggle', 'AIHub'ì™€ ê°™ì€ ë°ì´í„° í”Œë«í¼ì„ ê°™ì´ ì œê³µí•´ì¤˜.\n",
    "- ì‚¬ìš©ì í˜¼ì ë‘ ë‹¬ê°„ ì§„í–‰í•˜ëŠ” í”„ë¡œì íŠ¸ì„ì„ ê°ì•ˆí•´ì„œ Taskë¥¼ ì‘ì„±í•´\n",
    "- ê²°ê³¼ëŠ” ë°˜ë“œì‹œ í•œê¸€ë¡œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "</instructions>\n",
    "\n",
    "<Output_Format>\n",
    "{format_instructions}\n",
    "</Output_Format>\n",
    "\n",
    "\n",
    "<recommended_project>\n",
    "{recommended_project}\n",
    "</recommended_project>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_prompt = \"\"\"\n",
    "<Role>\n",
    "ë„Œ í”„ë¡œì íŠ¸ ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì•¼. ì¼ë°˜ì ì¸ í”„ë¡œì íŠ¸ ì£¼ì œë¥¼ êµ¬ì²´í™”í•˜ê³ , ì„¸ë¶€ ë‹¨ê³„ë¥¼ êµ¬ì„±í•˜ëŠ”ë° íŠ¹í™”ë˜ì–´ ìˆì–´.\n",
    "ì´ì „ í”„ë¡œì íŠ¸ì¸ 'prev_project'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©ìì˜ í¬ë§ ë‚œì´ë„ë¥¼ ë°˜ì˜í•´ì„œ í”„ë¡œì íŠ¸ë¥¼ êµ¬ì²´í™” í•´ì¤˜.\n",
    "</Role>\n",
    "\n",
    "<instructions>\n",
    "- Read through the all the below sections to get an understanding of the task.\n",
    "- í”„ë¡œì íŠ¸ëŠ” 6ë‹¨ê³„ë¡œ ë‚˜ëˆ„ê³ , ê° ë‹¨ê³„ë³„ ì„¸ë¶€ Taskë¥¼ í¬í•¨í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "- ì„¸ë¶€ Taskì˜ ì‘ì—… ë‹¨ìœ„ëŠ” ìµœëŒ€í•œ ì‘ê³  ì„¸ì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "- ê° TaskëŠ” êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ í¬í•¨í•´ ëª…í™•íˆ ì‘ì„±í•˜ì„¸ìš”.\n",
    "- ê° ì„¸ë¶€ Taskë§ˆë‹¤ í•™ìŠµì— ë„ì›€ì´ ë˜ëŠ” ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ê°™ì´ ì¶œë ¥í•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, Taskì˜ ë‚´ìš©ì´ 'ë°ì´í„° ìˆ˜ì§‘'ì´ë¼ë©´ 'Kaggle', 'AIHub'ì™€ ê°™ì€ ë°ì´í„° í”Œë«í¼ì„ ê°™ì´ ì œê³µí•´ì¤˜.\n",
    "- ì‚¬ìš©ì í˜¼ì ë‘ ë‹¬ê°„ ì§„í–‰í•˜ëŠ” í”„ë¡œì íŠ¸ì„ì„ ê°ì•ˆí•´ì„œ Taskë¥¼ ì‘ì„±í•´\n",
    "- ê²°ê³¼ëŠ” ë°˜ë“œì‹œ í•œê¸€ë¡œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "</instructions>\n",
    "\n",
    "<prev_project>\n",
    "{prev_project}\n",
    "</prev_project>\n",
    "\n",
    "<hope>\n",
    "í¬ë§ ë‚œì´ë„: {hopeLevel}\n",
    "</hope>\n",
    "\n",
    "<Output_Format>\n",
    "{format_instructions}\n",
    "</Output_Format>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "PATH = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/\"\n",
    "# input\n",
    "with open(PATH + \"input_base.json\", \"r\", encoding=\"utf-8\") as file: # base\n",
    "    input_base = json.load(file)\n",
    "with open(PATH + \"input_domain.json\", \"r\", encoding=\"utf-8\") as file: # base+domain\n",
    "    input_domain = json.load(file)\n",
    "\n",
    "# output\n",
    "with open(PATH + \"output_base.json\", \"r\", encoding=\"utf-8\") as file: # base\n",
    "    output_base = json.load(file)\n",
    "with open(PATH + \"output_level.json\", \"r\", encoding=\"utf-8\") as file: # base+level\n",
    "    output_level = json.load(file)\n",
    "with open(PATH + \"output_domain.json\", \"r\", encoding=\"utf-8\") as file: # base+domain\n",
    "    output_domain = json.load(file)\n",
    "with open(PATH + \"output_domain_level.json\", \"r\", encoding=\"utf-8\") as file: # base+domain+level\n",
    "    output_domain_level = json.load(file)\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "# base\n",
    "df = pd.DataFrame(columns=['input', 'output'])\n",
    "data = []\n",
    "j = 0\n",
    "for i, role in developer_roles:\n",
    "    for theme in input_base[i][role]['themes']:\n",
    "        data.append({\n",
    "            'gen_regen': 'gen',\n",
    "            'meta': 'base',\n",
    "            # 'role': role,\n",
    "            'input': theme,\n",
    "            'prompt': base_prompt,\n",
    "            'output': output_base[j][theme['title']]\n",
    "        })\n",
    "        j += 1\n",
    "df_base = pd.DataFrame(data)\n",
    "\n",
    "# level\n",
    "df_level = pd.concat([df_base] * 2, ignore_index=True)\n",
    "df_level['meta'] = 'level'\n",
    "df_level['prompt'] = level_prompt\n",
    "df_level['output'] = output_level\n",
    "df_level['gen_regen'] = 'regen'\n",
    "\n",
    "# domain\n",
    "df_domain = pd.DataFrame()\n",
    "df_domain['input'] = input_domain\n",
    "df_domain['prompt'] = base_prompt\n",
    "df_domain['output'] = output_domain\n",
    "df_domain['meta'] = 'domain'\n",
    "df_domain['gen_regen'] = 'gen'\n",
    "\n",
    "# domain_level\n",
    "df_domain_level = pd.concat([df_domain] * 2, ignore_index=True)\n",
    "df_domain_level['meta'] = 'domain_level'\n",
    "df_domain_level['output'] = output_domain_level\n",
    "df_domain_level['prompt'] = level_prompt\n",
    "df_domain_level['gen_regen'] = 'regen'\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ ë³‘í•©\n",
    "df_all = pd.concat([df_base, df_level, df_domain, df_domain_level], ignore_index=True)\n",
    "df_all.dropna(inplace=True)\n",
    "df_all['difficultyLevel'] = df_all['output'].apply(lambda x: x.get('difficultyLevel', None))\n",
    "\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genì´ë©´ inputì„, regenì´ë©´ input + difficultyLevelì„ promptì— ì„¤ì •\n",
    "os.chdir('/Users/no.2/Desktop/GitHub/cpplab-ai/project')\n",
    "from models.project_info import Project\n",
    "parser = JsonOutputParser(pydantic_object=Project)\n",
    "\n",
    "df_all[\"prompt\"] = df_all.apply(\n",
    "    lambda row: \n",
    "    row['prompt'].format(recommended_project = row['input'],\n",
    "                         format_instructions=parser.get_format_instructions()) if row[\"gen_regen\"] == \"gen\"\n",
    "    else row['prompt'].format(prev_project = row['input'],\n",
    "                                hopeLevel = row['difficultyLevel'],\n",
    "                                format_instructions=parser.get_format_instructions()),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "df_all.to_csv(PATH + \"all_data.csv\", index=False)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥ í™•ì¸\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "# genì´ 3000ê°œ regenì´ 6000ê°œ ì •ë„\n",
    "# test: genì—ì„œ 600ê°œ, regenì—ì„œ 1200ê°œ\n",
    "# train: ë‚˜ë¨¸ì§€\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_gen = df_all[df_all['gen_regen'] == 'gen']\n",
    "df_regen = df_all[df_all['gen_regen'] == 'regen']\n",
    "\n",
    "df_gen_train, df_gen_test = train_test_split(df_gen, test_size=600, random_state=42)\n",
    "df_regen_train, df_regen_test = train_test_split(df_regen, test_size=1200, random_state=42)\n",
    "\n",
    "df_train = pd.concat([df_gen_train, df_regen_train], ignore_index=True)\n",
    "df_test = pd.concat([df_gen_test, df_regen_test], ignore_index=True)\n",
    "\n",
    "df_train.to_csv(PATH + \"train_data.csv\", index=False)\n",
    "df_test.to_csv(PATH + \"test_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í—ˆê¹…í˜ì´ìŠ¤ì— ì €ì¥\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from huggingface_hub import notebook_login\n",
    "PATH = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/\"\n",
    "\n",
    "train_dataset = Dataset.from_csv(PATH+\"train_data.csv\")\n",
    "test_dataset = Dataset.from_csv(PATH+\"test_data.csv\")\n",
    "\n",
    "# Hugging Face DatasetDictë¡œ ë³€í™˜\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "# Hugging Faceì— ë°ì´í„°ì…‹ ì—…ë¡œë“œ\n",
    "dataset.push_to_hub(\"hyeongmin99/cpplab_sllm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
