{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "아래 프롬프트를 서로 다른 모델에 실행한 결과인데, 두 결과를 비교해서 어떤 결과가 더 좋은지 판단해줘.\n",
    "응답 형식은 1번 모델이 더 좋다면 '1', 2번 모델이 더 좋다면 '2'를 반환해줘.\n",
    "해당 모델을 선택한 이유도 작성해줘.\n",
    "결과는 json 형식으로 반환해.\n",
    "\n",
    "<prompt>\n",
    "{prompt}\n",
    "</prompt>\n",
    "\n",
    "<model1 결과>\n",
    "{model1}\n",
    "</model1>\n",
    "\n",
    "<model2 결과>\n",
    "{model2}\n",
    "</model2>\n",
    "\n",
    "<Output_Format>\n",
    "{{\"result\": 1 or 2, \"reason\": \"이유를 작성해주세요.\"}}\n",
    "</Output_Format>\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "prompt =  PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['prompt', 'model1', 'model2']\n",
    ")\n",
    "parser = JsonOutputParser()\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT 평가\n",
    "# finetuned vs not finetuned\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from tqdm.asyncio import tqdm  # 비동기 tqdm\n",
    "\n",
    "# 저장된 데이터 경로\n",
    "OUTPUT_FILE = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/finetuned_notfinetuned_eval_results.json\"\n",
    "FAILED_REQUESTS_FILE = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/finetuned_notfinetuned_eval_results.json\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"hyeongmin99/cpplab_sllm\")\n",
    "\n",
    "# 동시 작업 수 제한\n",
    "semaphore = asyncio.Semaphore(10)\n",
    "MAX_RETRIES = 3  # 최대 재시도 횟수\n",
    "\n",
    "# 기존 저장된 데이터 불러오기\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            results = json.load(f)\n",
    "            print(f\"✅ 기존 저장된 데이터 로드 성공 ({len(results)}개)\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"⚠️ 기존 데이터 로드 실패. 새로운 파일로 진행합니다.\")\n",
    "            results = [None] * len(dataset['test'])\n",
    "else:\n",
    "    results = [None] * len(dataset['test'])\n",
    "\n",
    "# None인 데이터만 다시 실행할 리스트 생성\n",
    "retry_indices = [i for i, result in enumerate(results) if result is None]\n",
    "print(f\"⚠️ {len(retry_indices)}개의 실패한 작업을 다시 시도합니다.\")\n",
    "\n",
    "# 실패한 요청 저장 리스트\n",
    "failed_requests = []\n",
    "\n",
    "with open('/Users/no.2/Desktop/GitHub/cpplab-sllm/data/inference_outputs/finetuned_outputs.json', \"r\", encoding=\"utf-8\") as file:\n",
    "    finetuened_outputs = json.load(file)\n",
    "with open('/Users/no.2/Desktop/GitHub/cpplab-sllm/data/inference_outputs/notfinetuned_outputs.json', \"r\", encoding=\"utf-8\") as file:\n",
    "    notfinetuened_outputs = json.load(file)\n",
    "\n",
    "# 비동기 호출을 위한 함수 정의\n",
    "async def generate_project_data(index, prompt, model1, model2, retries=0):\n",
    "    async with semaphore:  # 세마포어로 동시 호출 제한\n",
    "        input_data = {\"prompt\": prompt, \"model1\": model1, \"model2\": model2}\n",
    "        try:\n",
    "            result = await chain.ainvoke(input_data)\n",
    "            return index, result\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 오류 발생: {index} - {e}\")\n",
    "            if retries < MAX_RETRIES:\n",
    "                print(f\"🔄 재시도 {retries + 1}/{MAX_RETRIES} - {index}\")\n",
    "                return await generate_project_data(index, prompt, model1, model2, retries=retries + 1)\n",
    "            else:\n",
    "                print(f\"⚠️ {index} 처리 실패 (최대 재시도 도달)\")\n",
    "                failed_requests.append({\"index\": index, \"prompt\": prompt, \"model1\": model1, \"model2\": model2})\n",
    "                return index, None  # 실패한 요청은 None 반환\n",
    "\n",
    "# None인 값만 다시 실행하는 메인 함수\n",
    "async def retry_failed_tasks():\n",
    "    progress_bar = tqdm(total=len(retry_indices), unit=\"task\", disable=False)\n",
    "    # model 1 = finetuned, model 2 = not finetuned\n",
    "    tasks = [generate_project_data(i, dataset['test']['prompt'][i], finetuened_outputs[i], notfinetuened_outputs[i]) for i in retry_indices]\n",
    "    completed_count = 0\n",
    "\n",
    "    for future in asyncio.as_completed(tasks):\n",
    "        index, result = await future\n",
    "        results[index] = result\n",
    "        completed_count += 1\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        # 10개 단위로 진행률 출력 및 저장\n",
    "        if completed_count % 10 == 0:\n",
    "            progress_bar.n = completed_count\n",
    "            # progress_bar.refresh()\n",
    "            with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as json_file:\n",
    "                json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # 최종 결과 저장\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # 실패한 요청 저장\n",
    "    if failed_requests:\n",
    "        with open(FAILED_REQUESTS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(failed_requests, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"⚠️ {len(failed_requests)}개 요청 실패. {FAILED_REQUESTS_FILE}에 저장됨.\")\n",
    "\n",
    "    print(\"🎉 모든 작업 완료!\")\n",
    "\n",
    "# 비동기 실행\n",
    "await retry_failed_tasks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파인튜닝 후 결과가 더 좋은 경우: 1227개\n",
      "파인튜닝 전 결과가 더 좋은 경우: 573개\n",
      "파인튜닝 후 결과가 더 좋은 비율: 68.17%\n"
     ]
    }
   ],
   "source": [
    "with open (\"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/finetuned_notfinetuned_eval_results.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    gpteval_results = json.load(file)\n",
    "\n",
    "# 결과 확인\n",
    "cnt_1 = 0\n",
    "for i, result in enumerate(gpteval_results):\n",
    "    if int(result['result']) == 1:\n",
    "        cnt_1 += 1\n",
    "\n",
    "print(f\"파인튜닝 후 결과가 더 좋은 경우: {cnt_1}개\")\n",
    "print(f\"파인튜닝 전 결과가 더 좋은 경우: {len(gpteval_results) - cnt_1}개\")\n",
    "\n",
    "print(f\"파인튜닝 후 결과가 더 좋은 비율: {cnt_1 / len(gpteval_results) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT 평가\n",
    "# GPT vs fine-tuned\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from tqdm.asyncio import tqdm  # 비동기 tqdm\n",
    "\n",
    "# 저장된 데이터 경로\n",
    "OUTPUT_FILE = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/gpt_finetuned_eval_results.json\"\n",
    "FAILED_REQUESTS_FILE = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/gpt_fintuned_eval_failed_requests.json\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"hyeongmin99/cpplab_sllm\")\n",
    "\n",
    "# 동시 작업 수 제한\n",
    "semaphore = asyncio.Semaphore(15)\n",
    "MAX_RETRIES = 3  # 최대 재시도 횟수\n",
    "\n",
    "# 기존 저장된 데이터 불러오기\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            results = json.load(f)\n",
    "            print(f\"✅ 기존 저장된 데이터 로드 성공 ({len(results)}개)\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"⚠️ 기존 데이터 로드 실패. 새로운 파일로 진행합니다.\")\n",
    "            results = [None] * len(dataset['test'])\n",
    "else:\n",
    "    results = [None] * len(dataset['test'])\n",
    "\n",
    "# None인 데이터만 다시 실행할 리스트 생성\n",
    "retry_indices = [i for i, result in enumerate(results) if result is None]\n",
    "print(f\"⚠️ {len(retry_indices)}개의 실패한 작업을 다시 시도합니다.\")\n",
    "\n",
    "# 실패한 요청 저장 리스트\n",
    "failed_requests = []\n",
    "\n",
    "with open('/Users/no.2/Desktop/GitHub/cpplab-sllm/data/inference_outputs/finetuned_outputs.json', \"r\", encoding=\"utf-8\") as file:\n",
    "    finetuened_outputs = json.load(file)\n",
    "gpt_outputs = dataset['test']['output']\n",
    "\n",
    "# 비동기 호출을 위한 함수 정의\n",
    "async def generate_project_data(index, prompt, model1, model2, retries=0):\n",
    "    async with semaphore:  # 세마포어로 동시 호출 제한\n",
    "        input_data = {\"prompt\": prompt, \"model1\": model1, \"model2\": model2}\n",
    "        try:\n",
    "            result = await chain.ainvoke(input_data)\n",
    "            return index, result\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 오류 발생: {index} - {e}\")\n",
    "            if retries < MAX_RETRIES:\n",
    "                print(f\"🔄 재시도 {retries + 1}/{MAX_RETRIES} - {index}\")\n",
    "                return await generate_project_data(index, prompt, model1, model2, retries=retries + 1)\n",
    "            else:\n",
    "                print(f\"⚠️ {index} 처리 실패 (최대 재시도 도달)\")\n",
    "                failed_requests.append({\"index\": index, \"prompt\": prompt, \"model1\": model1, \"model2\": model2})\n",
    "                return index, None  # 실패한 요청은 None 반환\n",
    "\n",
    "# None인 값만 다시 실행하는 메인 함수\n",
    "async def retry_failed_tasks():\n",
    "    progress_bar = tqdm(total=len(retry_indices), unit=\"task\", disable=False)\n",
    "    # model 1 = finetuned, model 2 = gpt\n",
    "    tasks = [generate_project_data(i, dataset['test']['prompt'][i], finetuened_outputs[i], gpt_outputs[i]) for i in retry_indices]\n",
    "    completed_count = 0\n",
    "\n",
    "    for future in asyncio.as_completed(tasks):\n",
    "        index, result = await future\n",
    "        results[index] = result\n",
    "        completed_count += 1\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        # 10개 단위로 진행률 출력 및 저장\n",
    "        if completed_count % 10 == 0:\n",
    "            progress_bar.n = completed_count\n",
    "            # progress_bar.refresh()\n",
    "            with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as json_file:\n",
    "                json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # 최종 결과 저장\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # 실패한 요청 저장\n",
    "    if failed_requests:\n",
    "        with open(FAILED_REQUESTS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(failed_requests, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"⚠️ {len(failed_requests)}개 요청 실패. {FAILED_REQUESTS_FILE}에 저장됨.\")\n",
    "\n",
    "    print(\"🎉 모든 작업 완료!\")\n",
    "\n",
    "# 비동기 실행\n",
    "await retry_failed_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuned 모델이 더 좋은 결과를 보인 경우: 787개\n",
      "gpt 모델이 더 좋은 결과를 보인 경우: 1013개\n",
      "finetuned 모델이 더 좋은 비율: 43.72%\n"
     ]
    }
   ],
   "source": [
    "with open (\"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/gpt_finetuned_eval_results.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    gpteval_results = json.load(file)\n",
    "\n",
    "# 결과 확인\n",
    "cnt_1 = 0\n",
    "for i, result in enumerate(gpteval_results):\n",
    "    if int(result['result']) == 1:\n",
    "        cnt_1 += 1\n",
    "\n",
    "print(f\"finetuned 모델이 더 좋은 결과를 보인 경우: {cnt_1}개\")\n",
    "print(f\"gpt 모델이 더 좋은 결과를 보인 경우: {len(gpteval_results) - cnt_1}개\")\n",
    "# 비율\n",
    "print(f\"finetuned 모델이 더 좋은 비율: {cnt_1 / len(gpteval_results) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT 평가\n",
    "# GPT vs not fine-tuned\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from tqdm.asyncio import tqdm  # 비동기 tqdm\n",
    "\n",
    "# 저장된 데이터 경로\n",
    "OUTPUT_FILE = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/gpt_notfinetuned_eval_results.json\"\n",
    "FAILED_REQUESTS_FILE = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/gpt_notfintuned_eval_failed_requests.json\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"hyeongmin99/cpplab_sllm\")\n",
    "\n",
    "# 동시 작업 수 제한\n",
    "semaphore = asyncio.Semaphore(15)\n",
    "MAX_RETRIES = 3  # 최대 재시도 횟수\n",
    "\n",
    "# 기존 저장된 데이터 불러오기\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            results = json.load(f)\n",
    "            print(f\"✅ 기존 저장된 데이터 로드 성공 ({len(results)}개)\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"⚠️ 기존 데이터 로드 실패. 새로운 파일로 진행합니다.\")\n",
    "            results = [None] * len(dataset['test'])\n",
    "else:\n",
    "    results = [None] * len(dataset['test'])\n",
    "\n",
    "# None인 데이터만 다시 실행할 리스트 생성\n",
    "retry_indices = [i for i, result in enumerate(results) if result is None]\n",
    "print(f\"⚠️ {len(retry_indices)}개의 실패한 작업을 다시 시도합니다.\")\n",
    "\n",
    "# 실패한 요청 저장 리스트\n",
    "failed_requests = []\n",
    "\n",
    "with open('/Users/no.2/Desktop/GitHub/cpplab-sllm/data/inference_outputs/notfinetuned_outputs.json', \"r\", encoding=\"utf-8\") as file:\n",
    "    notfinetuened_outputs = json.load(file)\n",
    "gpt_outputs = dataset['test']['output']\n",
    "\n",
    "# 비동기 호출을 위한 함수 정의\n",
    "async def generate_project_data(index, prompt, model1, model2, retries=0):\n",
    "    async with semaphore:  # 세마포어로 동시 호출 제한\n",
    "        input_data = {\"prompt\": prompt, \"model1\": model1, \"model2\": model2}\n",
    "        try:\n",
    "            result = await chain.ainvoke(input_data)\n",
    "            return index, result\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 오류 발생: {index} - {e}\")\n",
    "            if retries < MAX_RETRIES:\n",
    "                print(f\"🔄 재시도 {retries + 1}/{MAX_RETRIES} - {index}\")\n",
    "                return await generate_project_data(index, prompt, model1, model2, retries=retries + 1)\n",
    "            else:\n",
    "                print(f\"⚠️ {index} 처리 실패 (최대 재시도 도달)\")\n",
    "                failed_requests.append({\"index\": index, \"prompt\": prompt, \"model1\": model1, \"model2\": model2})\n",
    "                return index, None  # 실패한 요청은 None 반환\n",
    "\n",
    "# None인 값만 다시 실행하는 메인 함수\n",
    "async def retry_failed_tasks():\n",
    "    progress_bar = tqdm(total=len(retry_indices), unit=\"task\", disable=False)\n",
    "    # model 1 = finetuned, model 2 = gpt\n",
    "    tasks = [generate_project_data(i, dataset['test']['prompt'][i], notfinetuened_outputs[i], gpt_outputs[i]) for i in retry_indices]\n",
    "    completed_count = 0\n",
    "\n",
    "    for future in asyncio.as_completed(tasks):\n",
    "        index, result = await future\n",
    "        results[index] = result\n",
    "        completed_count += 1\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        # 10개 단위로 진행률 출력 및 저장\n",
    "        if completed_count % 10 == 0:\n",
    "            progress_bar.n = completed_count\n",
    "            # progress_bar.refresh()\n",
    "            with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as json_file:\n",
    "                json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # 최종 결과 저장\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # 실패한 요청 저장\n",
    "    if failed_requests:\n",
    "        with open(FAILED_REQUESTS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(failed_requests, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"⚠️ {len(failed_requests)}개 요청 실패. {FAILED_REQUESTS_FILE}에 저장됨.\")\n",
    "\n",
    "    print(\"🎉 모든 작업 완료!\")\n",
    "\n",
    "# 비동기 실행\n",
    "await retry_failed_tasks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notfinetuned 모델이 더 좋은 결과를 보인 경우: 743개\n",
      "gpt 모델이 더 좋은 결과를 보인 경우: 1057개\n",
      "notfinetuned 모델이 더 좋은 비율: 41.28%\n"
     ]
    }
   ],
   "source": [
    "with open (\"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/gpt_notfinetuned_eval_results.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    gpteval_results = json.load(file)\n",
    "\n",
    "# 결과 확인\n",
    "cnt_1 = 0\n",
    "for i, result in enumerate(gpteval_results):\n",
    "    if int(result['result']) == 1:\n",
    "        cnt_1 += 1\n",
    "\n",
    "print(f\"notfinetuned 모델이 더 좋은 결과를 보인 경우: {cnt_1}개\")\n",
    "print(f\"gpt 모델이 더 좋은 결과를 보인 경우: {len(gpteval_results) - cnt_1}개\")\n",
    "\n",
    "print(f\"notfinetuned 모델이 더 좋은 비율: {cnt_1 / len(gpteval_results) * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
