{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "ì•„ë˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸ì— ì‹¤í–‰í•œ ê²°ê³¼ì¸ë°, ë‘ ê²°ê³¼ë¥¼ ë¹„êµí•´ì„œ ì–´ë–¤ ê²°ê³¼ê°€ ë” ì¢‹ì€ì§€ íŒë‹¨í•´ì¤˜.\n",
    "ì‘ë‹µ í˜•ì‹ì€ 1ë²ˆ ëª¨ë¸ì´ ë” ì¢‹ë‹¤ë©´ '1', 2ë²ˆ ëª¨ë¸ì´ ë” ì¢‹ë‹¤ë©´ '2'ë¥¼ ë°˜í™˜í•´ì¤˜.\n",
    "í•´ë‹¹ ëª¨ë¸ì„ ì„ íƒí•œ ì´ìœ ë„ ì‘ì„±í•´ì¤˜.\n",
    "ê²°ê³¼ëŠ” json í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´.\n",
    "\n",
    "<prompt>\n",
    "{prompt}\n",
    "</prompt>\n",
    "\n",
    "<model1 ê²°ê³¼>\n",
    "{model1}\n",
    "</model1>\n",
    "\n",
    "<model2 ê²°ê³¼>\n",
    "{model2}\n",
    "</model2>\n",
    "\n",
    "<Output_Format>\n",
    "{{\"result\": 1 or 2, \"reason\": \"ì´ìœ ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\"}}\n",
    "</Output_Format>\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "prompt =  PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['prompt', 'model1', 'model2']\n",
    ")\n",
    "parser = JsonOutputParser()\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT í‰ê°€\n",
    "# finetuned vs not finetuned\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from tqdm.asyncio import tqdm  # ë¹„ë™ê¸° tqdm\n",
    "\n",
    "# ì €ì¥ëœ ë°ì´í„° ê²½ë¡œ\n",
    "OUTPUT_FILE = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/finetuned_notfinetuned_eval_results.json\"\n",
    "FAILED_REQUESTS_FILE = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/finetuned_notfinetuned_eval_results.json\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"hyeongmin99/cpplab_sllm\")\n",
    "\n",
    "# ë™ì‹œ ì‘ì—… ìˆ˜ ì œí•œ\n",
    "semaphore = asyncio.Semaphore(10)\n",
    "MAX_RETRIES = 3  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜\n",
    "\n",
    "# ê¸°ì¡´ ì €ì¥ëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            results = json.load(f)\n",
    "            print(f\"âœ… ê¸°ì¡´ ì €ì¥ëœ ë°ì´í„° ë¡œë“œ ì„±ê³µ ({len(results)}ê°œ)\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"âš ï¸ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨. ìƒˆë¡œìš´ íŒŒì¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "            results = [None] * len(dataset['test'])\n",
    "else:\n",
    "    results = [None] * len(dataset['test'])\n",
    "\n",
    "# Noneì¸ ë°ì´í„°ë§Œ ë‹¤ì‹œ ì‹¤í–‰í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "retry_indices = [i for i, result in enumerate(results) if result is None]\n",
    "print(f\"âš ï¸ {len(retry_indices)}ê°œì˜ ì‹¤íŒ¨í•œ ì‘ì—…ì„ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ì‹¤íŒ¨í•œ ìš”ì²­ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "failed_requests = []\n",
    "\n",
    "with open('/Users/no.2/Desktop/GitHub/cpplab-sllm/data/inference_outputs/finetuned_outputs.json', \"r\", encoding=\"utf-8\") as file:\n",
    "    finetuened_outputs = json.load(file)\n",
    "with open('/Users/no.2/Desktop/GitHub/cpplab-sllm/data/inference_outputs/notfinetuned_outputs.json', \"r\", encoding=\"utf-8\") as file:\n",
    "    notfinetuened_outputs = json.load(file)\n",
    "\n",
    "# ë¹„ë™ê¸° í˜¸ì¶œì„ ìœ„í•œ í•¨ìˆ˜ ì •ì˜\n",
    "async def generate_project_data(index, prompt, model1, model2, retries=0):\n",
    "    async with semaphore:  # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ í˜¸ì¶œ ì œí•œ\n",
    "        input_data = {\"prompt\": prompt, \"model1\": model1, \"model2\": model2}\n",
    "        try:\n",
    "            result = await chain.ainvoke(input_data)\n",
    "            return index, result\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {index} - {e}\")\n",
    "            if retries < MAX_RETRIES:\n",
    "                print(f\"ğŸ”„ ì¬ì‹œë„ {retries + 1}/{MAX_RETRIES} - {index}\")\n",
    "                return await generate_project_data(index, prompt, model1, model2, retries=retries + 1)\n",
    "            else:\n",
    "                print(f\"âš ï¸ {index} ì²˜ë¦¬ ì‹¤íŒ¨ (ìµœëŒ€ ì¬ì‹œë„ ë„ë‹¬)\")\n",
    "                failed_requests.append({\"index\": index, \"prompt\": prompt, \"model1\": model1, \"model2\": model2})\n",
    "                return index, None  # ì‹¤íŒ¨í•œ ìš”ì²­ì€ None ë°˜í™˜\n",
    "\n",
    "# Noneì¸ ê°’ë§Œ ë‹¤ì‹œ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜\n",
    "async def retry_failed_tasks():\n",
    "    progress_bar = tqdm(total=len(retry_indices), unit=\"task\", disable=False)\n",
    "    # model 1 = finetuned, model 2 = not finetuned\n",
    "    tasks = [generate_project_data(i, dataset['test']['prompt'][i], finetuened_outputs[i], notfinetuened_outputs[i]) for i in retry_indices]\n",
    "    completed_count = 0\n",
    "\n",
    "    for future in asyncio.as_completed(tasks):\n",
    "        index, result = await future\n",
    "        results[index] = result\n",
    "        completed_count += 1\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        # 10ê°œ ë‹¨ìœ„ë¡œ ì§„í–‰ë¥  ì¶œë ¥ ë° ì €ì¥\n",
    "        if completed_count % 10 == 0:\n",
    "            progress_bar.n = completed_count\n",
    "            # progress_bar.refresh()\n",
    "            with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as json_file:\n",
    "                json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # ìµœì¢… ê²°ê³¼ ì €ì¥\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # ì‹¤íŒ¨í•œ ìš”ì²­ ì €ì¥\n",
    "    if failed_requests:\n",
    "        with open(FAILED_REQUESTS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(failed_requests, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"âš ï¸ {len(failed_requests)}ê°œ ìš”ì²­ ì‹¤íŒ¨. {FAILED_REQUESTS_FILE}ì— ì €ì¥ë¨.\")\n",
    "\n",
    "    print(\"ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!\")\n",
    "\n",
    "# ë¹„ë™ê¸° ì‹¤í–‰\n",
    "await retry_failed_tasks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íŒŒì¸íŠœë‹ í›„ ê²°ê³¼ê°€ ë” ì¢‹ì€ ê²½ìš°: 1227ê°œ\n",
      "íŒŒì¸íŠœë‹ ì „ ê²°ê³¼ê°€ ë” ì¢‹ì€ ê²½ìš°: 573ê°œ\n",
      "íŒŒì¸íŠœë‹ í›„ ê²°ê³¼ê°€ ë” ì¢‹ì€ ë¹„ìœ¨: 68.17%\n"
     ]
    }
   ],
   "source": [
    "with open (\"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/finetuned_notfinetuned_eval_results.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    gpteval_results = json.load(file)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "cnt_1 = 0\n",
    "for i, result in enumerate(gpteval_results):\n",
    "    if int(result['result']) == 1:\n",
    "        cnt_1 += 1\n",
    "\n",
    "print(f\"íŒŒì¸íŠœë‹ í›„ ê²°ê³¼ê°€ ë” ì¢‹ì€ ê²½ìš°: {cnt_1}ê°œ\")\n",
    "print(f\"íŒŒì¸íŠœë‹ ì „ ê²°ê³¼ê°€ ë” ì¢‹ì€ ê²½ìš°: {len(gpteval_results) - cnt_1}ê°œ\")\n",
    "\n",
    "print(f\"íŒŒì¸íŠœë‹ í›„ ê²°ê³¼ê°€ ë” ì¢‹ì€ ë¹„ìœ¨: {cnt_1 / len(gpteval_results) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT í‰ê°€\n",
    "# GPT vs fine-tuned\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from tqdm.asyncio import tqdm  # ë¹„ë™ê¸° tqdm\n",
    "\n",
    "# ì €ì¥ëœ ë°ì´í„° ê²½ë¡œ\n",
    "OUTPUT_FILE = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/gpt_finetuned_eval_results.json\"\n",
    "FAILED_REQUESTS_FILE = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/gpt_fintuned_eval_failed_requests.json\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"hyeongmin99/cpplab_sllm\")\n",
    "\n",
    "# ë™ì‹œ ì‘ì—… ìˆ˜ ì œí•œ\n",
    "semaphore = asyncio.Semaphore(15)\n",
    "MAX_RETRIES = 3  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜\n",
    "\n",
    "# ê¸°ì¡´ ì €ì¥ëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            results = json.load(f)\n",
    "            print(f\"âœ… ê¸°ì¡´ ì €ì¥ëœ ë°ì´í„° ë¡œë“œ ì„±ê³µ ({len(results)}ê°œ)\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"âš ï¸ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨. ìƒˆë¡œìš´ íŒŒì¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "            results = [None] * len(dataset['test'])\n",
    "else:\n",
    "    results = [None] * len(dataset['test'])\n",
    "\n",
    "# Noneì¸ ë°ì´í„°ë§Œ ë‹¤ì‹œ ì‹¤í–‰í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "retry_indices = [i for i, result in enumerate(results) if result is None]\n",
    "print(f\"âš ï¸ {len(retry_indices)}ê°œì˜ ì‹¤íŒ¨í•œ ì‘ì—…ì„ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ì‹¤íŒ¨í•œ ìš”ì²­ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "failed_requests = []\n",
    "\n",
    "with open('/Users/no.2/Desktop/GitHub/cpplab-sllm/data/inference_outputs/finetuned_outputs.json', \"r\", encoding=\"utf-8\") as file:\n",
    "    finetuened_outputs = json.load(file)\n",
    "gpt_outputs = dataset['test']['output']\n",
    "\n",
    "# ë¹„ë™ê¸° í˜¸ì¶œì„ ìœ„í•œ í•¨ìˆ˜ ì •ì˜\n",
    "async def generate_project_data(index, prompt, model1, model2, retries=0):\n",
    "    async with semaphore:  # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ í˜¸ì¶œ ì œí•œ\n",
    "        input_data = {\"prompt\": prompt, \"model1\": model1, \"model2\": model2}\n",
    "        try:\n",
    "            result = await chain.ainvoke(input_data)\n",
    "            return index, result\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {index} - {e}\")\n",
    "            if retries < MAX_RETRIES:\n",
    "                print(f\"ğŸ”„ ì¬ì‹œë„ {retries + 1}/{MAX_RETRIES} - {index}\")\n",
    "                return await generate_project_data(index, prompt, model1, model2, retries=retries + 1)\n",
    "            else:\n",
    "                print(f\"âš ï¸ {index} ì²˜ë¦¬ ì‹¤íŒ¨ (ìµœëŒ€ ì¬ì‹œë„ ë„ë‹¬)\")\n",
    "                failed_requests.append({\"index\": index, \"prompt\": prompt, \"model1\": model1, \"model2\": model2})\n",
    "                return index, None  # ì‹¤íŒ¨í•œ ìš”ì²­ì€ None ë°˜í™˜\n",
    "\n",
    "# Noneì¸ ê°’ë§Œ ë‹¤ì‹œ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜\n",
    "async def retry_failed_tasks():\n",
    "    progress_bar = tqdm(total=len(retry_indices), unit=\"task\", disable=False)\n",
    "    # model 1 = finetuned, model 2 = gpt\n",
    "    tasks = [generate_project_data(i, dataset['test']['prompt'][i], finetuened_outputs[i], gpt_outputs[i]) for i in retry_indices]\n",
    "    completed_count = 0\n",
    "\n",
    "    for future in asyncio.as_completed(tasks):\n",
    "        index, result = await future\n",
    "        results[index] = result\n",
    "        completed_count += 1\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        # 10ê°œ ë‹¨ìœ„ë¡œ ì§„í–‰ë¥  ì¶œë ¥ ë° ì €ì¥\n",
    "        if completed_count % 10 == 0:\n",
    "            progress_bar.n = completed_count\n",
    "            # progress_bar.refresh()\n",
    "            with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as json_file:\n",
    "                json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # ìµœì¢… ê²°ê³¼ ì €ì¥\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # ì‹¤íŒ¨í•œ ìš”ì²­ ì €ì¥\n",
    "    if failed_requests:\n",
    "        with open(FAILED_REQUESTS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(failed_requests, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"âš ï¸ {len(failed_requests)}ê°œ ìš”ì²­ ì‹¤íŒ¨. {FAILED_REQUESTS_FILE}ì— ì €ì¥ë¨.\")\n",
    "\n",
    "    print(\"ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!\")\n",
    "\n",
    "# ë¹„ë™ê¸° ì‹¤í–‰\n",
    "await retry_failed_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuned ëª¨ë¸ì´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì¸ ê²½ìš°: 787ê°œ\n",
      "gpt ëª¨ë¸ì´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì¸ ê²½ìš°: 1013ê°œ\n",
      "finetuned ëª¨ë¸ì´ ë” ì¢‹ì€ ë¹„ìœ¨: 43.72%\n"
     ]
    }
   ],
   "source": [
    "with open (\"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/gpt_finetuned_eval_results.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    gpteval_results = json.load(file)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "cnt_1 = 0\n",
    "for i, result in enumerate(gpteval_results):\n",
    "    if int(result['result']) == 1:\n",
    "        cnt_1 += 1\n",
    "\n",
    "print(f\"finetuned ëª¨ë¸ì´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì¸ ê²½ìš°: {cnt_1}ê°œ\")\n",
    "print(f\"gpt ëª¨ë¸ì´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì¸ ê²½ìš°: {len(gpteval_results) - cnt_1}ê°œ\")\n",
    "# ë¹„ìœ¨\n",
    "print(f\"finetuned ëª¨ë¸ì´ ë” ì¢‹ì€ ë¹„ìœ¨: {cnt_1 / len(gpteval_results) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT í‰ê°€\n",
    "# GPT vs not fine-tuned\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from tqdm.asyncio import tqdm  # ë¹„ë™ê¸° tqdm\n",
    "\n",
    "# ì €ì¥ëœ ë°ì´í„° ê²½ë¡œ\n",
    "OUTPUT_FILE = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/gpt_notfinetuned_eval_results.json\"\n",
    "FAILED_REQUESTS_FILE = \"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/gpt_notfintuned_eval_failed_requests.json\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"hyeongmin99/cpplab_sllm\")\n",
    "\n",
    "# ë™ì‹œ ì‘ì—… ìˆ˜ ì œí•œ\n",
    "semaphore = asyncio.Semaphore(15)\n",
    "MAX_RETRIES = 3  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜\n",
    "\n",
    "# ê¸°ì¡´ ì €ì¥ëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            results = json.load(f)\n",
    "            print(f\"âœ… ê¸°ì¡´ ì €ì¥ëœ ë°ì´í„° ë¡œë“œ ì„±ê³µ ({len(results)}ê°œ)\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"âš ï¸ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨. ìƒˆë¡œìš´ íŒŒì¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "            results = [None] * len(dataset['test'])\n",
    "else:\n",
    "    results = [None] * len(dataset['test'])\n",
    "\n",
    "# Noneì¸ ë°ì´í„°ë§Œ ë‹¤ì‹œ ì‹¤í–‰í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "retry_indices = [i for i, result in enumerate(results) if result is None]\n",
    "print(f\"âš ï¸ {len(retry_indices)}ê°œì˜ ì‹¤íŒ¨í•œ ì‘ì—…ì„ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ì‹¤íŒ¨í•œ ìš”ì²­ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "failed_requests = []\n",
    "\n",
    "with open('/Users/no.2/Desktop/GitHub/cpplab-sllm/data/inference_outputs/notfinetuned_outputs.json', \"r\", encoding=\"utf-8\") as file:\n",
    "    notfinetuened_outputs = json.load(file)\n",
    "gpt_outputs = dataset['test']['output']\n",
    "\n",
    "# ë¹„ë™ê¸° í˜¸ì¶œì„ ìœ„í•œ í•¨ìˆ˜ ì •ì˜\n",
    "async def generate_project_data(index, prompt, model1, model2, retries=0):\n",
    "    async with semaphore:  # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ í˜¸ì¶œ ì œí•œ\n",
    "        input_data = {\"prompt\": prompt, \"model1\": model1, \"model2\": model2}\n",
    "        try:\n",
    "            result = await chain.ainvoke(input_data)\n",
    "            return index, result\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {index} - {e}\")\n",
    "            if retries < MAX_RETRIES:\n",
    "                print(f\"ğŸ”„ ì¬ì‹œë„ {retries + 1}/{MAX_RETRIES} - {index}\")\n",
    "                return await generate_project_data(index, prompt, model1, model2, retries=retries + 1)\n",
    "            else:\n",
    "                print(f\"âš ï¸ {index} ì²˜ë¦¬ ì‹¤íŒ¨ (ìµœëŒ€ ì¬ì‹œë„ ë„ë‹¬)\")\n",
    "                failed_requests.append({\"index\": index, \"prompt\": prompt, \"model1\": model1, \"model2\": model2})\n",
    "                return index, None  # ì‹¤íŒ¨í•œ ìš”ì²­ì€ None ë°˜í™˜\n",
    "\n",
    "# Noneì¸ ê°’ë§Œ ë‹¤ì‹œ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜\n",
    "async def retry_failed_tasks():\n",
    "    progress_bar = tqdm(total=len(retry_indices), unit=\"task\", disable=False)\n",
    "    # model 1 = finetuned, model 2 = gpt\n",
    "    tasks = [generate_project_data(i, dataset['test']['prompt'][i], notfinetuened_outputs[i], gpt_outputs[i]) for i in retry_indices]\n",
    "    completed_count = 0\n",
    "\n",
    "    for future in asyncio.as_completed(tasks):\n",
    "        index, result = await future\n",
    "        results[index] = result\n",
    "        completed_count += 1\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        # 10ê°œ ë‹¨ìœ„ë¡œ ì§„í–‰ë¥  ì¶œë ¥ ë° ì €ì¥\n",
    "        if completed_count % 10 == 0:\n",
    "            progress_bar.n = completed_count\n",
    "            # progress_bar.refresh()\n",
    "            with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as json_file:\n",
    "                json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # ìµœì¢… ê²°ê³¼ ì €ì¥\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # ì‹¤íŒ¨í•œ ìš”ì²­ ì €ì¥\n",
    "    if failed_requests:\n",
    "        with open(FAILED_REQUESTS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(failed_requests, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"âš ï¸ {len(failed_requests)}ê°œ ìš”ì²­ ì‹¤íŒ¨. {FAILED_REQUESTS_FILE}ì— ì €ì¥ë¨.\")\n",
    "\n",
    "    print(\"ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!\")\n",
    "\n",
    "# ë¹„ë™ê¸° ì‹¤í–‰\n",
    "await retry_failed_tasks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notfinetuned ëª¨ë¸ì´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì¸ ê²½ìš°: 743ê°œ\n",
      "gpt ëª¨ë¸ì´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì¸ ê²½ìš°: 1057ê°œ\n",
      "notfinetuned ëª¨ë¸ì´ ë” ì¢‹ì€ ë¹„ìœ¨: 41.28%\n"
     ]
    }
   ],
   "source": [
    "with open (\"/Users/no.2/Desktop/GitHub/cpplab-sllm/data/eval_results/gpt_notfinetuned_eval_results.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    gpteval_results = json.load(file)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "cnt_1 = 0\n",
    "for i, result in enumerate(gpteval_results):\n",
    "    if int(result['result']) == 1:\n",
    "        cnt_1 += 1\n",
    "\n",
    "print(f\"notfinetuned ëª¨ë¸ì´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì¸ ê²½ìš°: {cnt_1}ê°œ\")\n",
    "print(f\"gpt ëª¨ë¸ì´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì¸ ê²½ìš°: {len(gpteval_results) - cnt_1}ê°œ\")\n",
    "\n",
    "print(f\"notfinetuned ëª¨ë¸ì´ ë” ì¢‹ì€ ë¹„ìœ¨: {cnt_1 / len(gpteval_results) * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
